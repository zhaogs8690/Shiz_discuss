********************************************************************************
* 适用场景：何时使用 DDML（Double/Debiased Machine Learning）
********************************************************************************
* DDML 适用于因果推断问题，特别是在以下情况时推荐使用：
* 1. **高维控制变量（X）**：
*    - 传统 OLS 方法可能面临多重共线性问题，DDML 结合机器学习可以更好地估计 E[D|X] 和 E[Y|X]。
* 2. **存在潜在非线性关系**：
*    - 处理变量 D 或因变量 Y 可能与控制变量 X 存在复杂的非线性关系，传统线性回归可能无法准确建模。
* 3. **样本量适中或较大**：
*    - 由于 DDML 采用交叉拟合（cross-fitting），在小样本情况下可能会导致不稳定结果，一般推荐在样本量较大的情况下使用。
* 4. **关注因果推断，而非预测**：
*    - 主要目标是估计处理变量 D 对因变量 Y 的因果效应，而非单纯的预测任务。

********************************************************************************
* 机器学习方法选择：用于估计 E[D|X] 和 E[Y|X] 的方法
********************************************************************************
* DDML 允许使用多种机器学习方法来估计条件期望 E[D|X] 和 E[Y|X]，不同方法适用于不同场景：
*
* 1. **线性回归（regress）**
*    - **特点**：适用于线性关系，计算速度快，解释性强。
*    - **适用场景**：当控制变量数量较少，且与因变量/处理变量之间的关系接近线性。
*    - **代码示例**：`ddml E[D|X]: regress $D $X`
*
* 2. **Lasso 回归（lasso）**
*    - **特点**：适用于高维数据，能够自动进行变量选择，避免过拟合。
*    - **适用场景**：当 X 维度较高，但其中只有部分变量真正影响 D 或 Y。
*    - **代码示例**：`ddml E[D|X]: lasso $D $X`
*
* 3. **Ridge 回归（ridge）**
*    - **特点**：适用于多重共线性较强的数据，能够平滑参数估计，减少过拟合。
*    - **适用场景**：当 X 维度较高，且变量间存在较强的相关性。
*    - **代码示例**：`ddml E[D|X]: ridge $D $X`
*
* 4. **随机森林（rf, random forest）**
*    - **特点**：非线性建模能力强，能够自动捕捉变量间复杂交互关系。
*    - **适用场景**：当 D 或 Y 可能与 X 具有复杂的非线性关系时。
*    - **代码示例**：`ddml E[D|X]: rf $D $X`
*
* 5. **梯度提升树（gbm, gradient boosting machine）**
*    - **特点**：比随机森林更强的非线性建模能力，适用于大样本数据。
*    - **适用场景**：当变量之间存在复杂交互关系，并且样本量足够大时。
*    - **代码示例**：`ddml E[D|X]: gbm $D $X`
*
* 6. **神经网络（neural network, nn）**
*    - **特点**：适用于高度非线性的数据，但计算量较大，参数调优要求高。
*    - **适用场景**：当 X 维度非常高，且变量间可能存在高度复杂的交互关系时。
*    - **代码示例**：`ddml E[D|X]: nn $D $X`
*
********************************************************************************
* Stata DDML 代码实现
********************************************************************************
* 设置 Stata 处理空单元格方式
set emptycells drop

* 定义因变量（Y），这里是储蓄率（savingrate）
global Y savingrate

* 定义控制变量（X），包括：
* - 个人特征：old_num（老年人口数）、work_count（工作人数）、age（年龄）、agesq（年龄平方）
* - 教育水平：edu_y（教育年限）
* - 健康和婚姻状况：health_status（健康状况）、marriage（婚姻状况）
* - 风险偏好：risk_averse（风险厌恶）、risk_prefer（风险偏好）
* - 经济状况：lntotal_asset（总资产的对数）、lntotal_debt（总债务的对数）
* - 居住环境：public（是否为公房）、rural（是否为农村户口）
* - 时间和地区固定效应：i.year（年份虚拟变量）、i.city_lab（城市虚拟变量）
global X old_num work_count age agesq edu_y health_status marriage risk_averse risk_prefer lntotal_asset lntotal_debt public rural i.year i.city_lab

* 定义处理变量（D），这里是子女数量（children_num）
global D children_num

* 设定随机种子，保证结果的可重复性
set seed 42  
* `set seed` 影响随机过程，使结果可复现
* - 改变 `42` 为其他数（如 `set seed 1234`）会导致交叉验证的数据划分不同，但不影响模型结构
* - 省略 `set seed` 则每次运行可能得到不同结果

* 初始化 Double/Debiased Machine Learning (DDML) 过程，并进行 3 折交叉验证
ddml init partial, kfolds(3)  
* `kfolds(3)` 指定 3 折交叉验证：
* - 增大（如 `kfolds(5)` 或 `kfolds(10)`）可提高模型的稳定性，但计算量增加
* - 减小（如 `kfolds(2)`）计算更快，但可能导致估计不稳定
* - `kfolds(5)` 或 `kfolds(10)` 通常是推荐的折数

* 对处理变量 D（children_num）估计其条件期望 E[D|X]
ddml E[D|X]: regress $D $X  
* 可替换 `regress` 为 `lasso`、`ridge` 或 `rf` 等方法

* 对因变量 Y（savingrate）估计其条件期望 E[Y|X]
ddml E[Y|X]: regress $Y $X  
* 可替换 `regress` 为 `lasso`、`ridge` 或 `rf` 等方法

* 进行交叉拟合（cross-fitting），减少偏误
ddml crossfit  

* 估计因变量 Y 对处理变量 D 的影响，并使用稳健标准误
ddml estimate, robust  
* `robust` 选项用于控制异方差，提高稳健性
